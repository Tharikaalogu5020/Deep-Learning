import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense
from sklearn.preprocessing import StandardScaler

# Example synthetic dataset (replace with your transaction data)
np.random.seed(0)
normal_data = np.random.normal(0, 1, (1000, 20))
outliers = np.random.uniform(low=-4, high=4, size=(50, 20))
data = np.vstack([normal_data, outliers])

scaler = StandardScaler()
data_scaled = scaler.fit_transform(data)

# Autoencoder model
input_dim = data_scaled.shape[1]
input_layer = Input(shape=(input_dim,))
encoder = Dense(14, activation="relu")(input_layer)
encoder = Dense(7, activation="relu")(encoder)
decoder = Dense(14, activation='relu')(encoder)
decoder = Dense(input_dim, activation='linear')(decoder)
autoencoder = Model(inputs=input_layer, outputs=decoder)

autoencoder.compile(optimizer='adam', loss='mse')
autoencoder.fit(data_scaled, data_scaled, epochs=50, batch_size=32, validation_split=0.2)

# Detect anomalies by reconstruction error
reconstructions = autoencoder.predict(data_scaled)
mse = np.mean(np.power(data_scaled - reconstructions, 2), axis=1)
threshold = np.percentile(mse, 95)  # Top 5% as anomalies
outliers_detected = mse > threshold

print(f"Detected {np.sum(outliers_detected)} outliers")
